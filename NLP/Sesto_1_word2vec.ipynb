{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sesto_1 - word2vec_Sesto.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ue5hxxkdAQJg"
      },
      "source": [
        "<a href=\"https://www.inove.com.ar\"><img src=\"https://github.com/hernancontigiani/ceia_memorias_especializacion/raw/master/Figures/logoFIUBA.jpg\" width=\"500\" align=\"center\"></a>\n",
        "\n",
        "\n",
        "# Procesamiento de lenguaje natural\n",
        "## Word2vect\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCED1hh-Ioyf"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUbfVnzIIoMj"
      },
      "source": [
        "def cosine_similarity(a, b):\n",
        "    return np.dot(a, b) / (np.linalg.norm(a) * (np.linalg.norm(b)))"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMOa4JPSCJ29"
      },
      "source": [
        "### Datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIO7b8GjAC17"
      },
      "source": [
        "corpus = np.array(['que dia es hoy', 'martes el dia de hoy es martes', 'martes muchas gracias'])"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WqdaTmO8P1r"
      },
      "source": [
        "Documento 1 --> que dia es hoy \\\n",
        "Documento 2 --> martes el dia de hoy es martes \\\n",
        "Documento 3 --> martes muchas gracias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqcpv0eS8cdR"
      },
      "source": [
        "# Voculario --> son todas las palabras \"únicas o sin repetir que aparecen en nuestro courpus\"\n",
        "vocab = ['que', 'dia', 'es', 'hoy', 'martes', 'el', 'muchas', 'gracias']"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xdp1iU428_PQ"
      },
      "source": [
        "doc_1 = 'que dia es hoy'\n",
        "resultado = ['que', 'dia', 'es', 'hoy']"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKUvVVkH9e42",
        "outputId": "7377b6a6-c96e-46a4-c6dd-47e4a2cf6807"
      },
      "source": [
        "doc_1.split(\" \")"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['que', 'dia', 'es', 'hoy']"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XjJUL9g49ptU",
        "outputId": "359b366c-96de-43ca-8bf7-d7e8f2ab0069"
      },
      "source": [
        "'''\n",
        "[\n",
        "    ['que', 'dia', 'es', 'hoy'],\n",
        "    ['que', 'dia', 'es', 'hoy'],\n",
        "    ['que', 'dia', 'es', 'hoy']\n",
        "]\n",
        "'''\n",
        "corpus_terminos = []\n",
        "for doc in corpus:\n",
        "    terminos = doc.split(\" \")\n",
        "    corpus_terminos.append(terminos)\n",
        "\n",
        "corpus_terminos"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['que', 'dia', 'es', 'hoy'],\n",
              " ['martes', 'el', 'dia', 'de', 'hoy', 'es', 'martes'],\n",
              " ['martes', 'muchas', 'gracias']]"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RV0o8d50-efJ",
        "outputId": "4e6e9fe2-0eef-4724-8608-091b3f0e1bde"
      },
      "source": [
        "vocab_completo = np.sum(corpus_terminos)  # se hace un Set en ves de listas\n",
        "vocab_completo"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['que',\n",
              " 'dia',\n",
              " 'es',\n",
              " 'hoy',\n",
              " 'martes',\n",
              " 'el',\n",
              " 'dia',\n",
              " 'de',\n",
              " 'hoy',\n",
              " 'es',\n",
              " 'martes',\n",
              " 'martes',\n",
              " 'muchas',\n",
              " 'gracias']"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKZtPEAa_Fel",
        "outputId": "06882c06-0983-4ab4-d064-855318513341"
      },
      "source": [
        "vocab_1 = set(vocab_completo)\n",
        "vocab_1"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'de', 'dia', 'el', 'es', 'gracias', 'hoy', 'martes', 'muchas', 'que'}"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ht6QIwUE_Nuk",
        "outputId": "bace0cf7-ae4c-4f34-8e8a-1c9133ceeb5a"
      },
      "source": [
        "vocab_2 = np.unique(vocab_completo)\n",
        "vocab_2"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['de', 'dia', 'el', 'es', 'gracias', 'hoy', 'martes', 'muchas',\n",
              "       'que'], dtype='<U7')"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y62w_zfC_R8z"
      },
      "source": [
        "vocab = vocab_2"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-Yc-SQx_XBM",
        "outputId": "733f19c4-6466-4691-9158-42d0baf986de"
      },
      "source": [
        "vocab"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['de', 'dia', 'el', 'es', 'gracias', 'hoy', 'martes', 'muchas',\n",
              "       'que'], dtype='<U7')"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZBaQcLr_gEX",
        "outputId": "e5d02ef8-7555-43b3-f3bb-3169b1af1a52"
      },
      "source": [
        "vocab.shape"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9,)"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVHxBRNzCMOS"
      },
      "source": [
        "### 1 - Obtener el vocabulario del corpus (los términos utilizados)\n",
        "- Cada documento transformarlo en una lista de términos\n",
        "- Armar un vector de términos no repetidos de todos los documentos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZqTOZzDI7uv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aec4fd5b-795a-45c2-c18c-184fbff878cf"
      },
      "source": [
        "corpus_terminos = []\n",
        "for doc in corpus:\n",
        "    terminos = doc.split(\" \")\n",
        "    corpus_terminos.append(terminos)\n",
        "\n",
        "# Se obtiene un corpus que es una lista de listas de términos:\n",
        "#a,b = corpus_terminos.shape()\n",
        "corpus_len = len(corpus_terminos)\n",
        "print(\"Longitud del corpus: \", corpus_len)\n",
        "corpus_terminos"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Longitud del corpus:  3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['que', 'dia', 'es', 'hoy'],\n",
              " ['martes', 'el', 'dia', 'de', 'hoy', 'es', 'martes'],\n",
              " ['martes', 'muchas', 'gracias']]"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CxSPsCi_bPgm",
        "outputId": "4b03b9a8-ac15-473d-f3a5-4d25776adb9d"
      },
      "source": [
        "np.warnings.filterwarnings('ignore', category=np.VisibleDeprecationWarning)                 \n",
        "vocab_completo = np.sum(corpus_terminos)\n",
        "vocab_unique = np.unique(vocab_completo)\n",
        "vocab_len = int(len(vocab_unique))\n",
        "print(vocab_completo)\n",
        "print(\"El vocabulario del corpus es: \")\n",
        "print(vocab_unique)\n",
        "print(\"Longitud del vocabulario: \", vocab_len)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['que', 'dia', 'es', 'hoy', 'martes', 'el', 'dia', 'de', 'hoy', 'es', 'martes', 'martes', 'muchas', 'gracias']\n",
            "El vocabulario del corpus es: \n",
            "['de' 'dia' 'el' 'es' 'gracias' 'hoy' 'martes' 'muchas' 'que']\n",
            "Longitud del vocabulario:  9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUhH983FI7It"
      },
      "source": [
        "### 2- OneHot encoding\n",
        "Data una lista de textos, devolver una matriz con la representación oneHotEncoding de estos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Os0AAQo6I6Z1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b73b8ae2-8a44-4d5b-a86e-512393af4cb5"
      },
      "source": [
        "# Tengo el corpus, el vocabulario y sus longitudes\n",
        "# Creo la matriz de OneHotEncoding\n",
        "# Recorro cada documento y con eso recorro el vocabulario, si el termino \n",
        "# del vocabulario se encuentra en el documento, modifico la matriz de datos.\n",
        "ohe = np.zeros((corpus_len,vocab_len))\n",
        "\n",
        "for i,doc in enumerate(corpus_terminos):\n",
        "  for j, vocab_term in enumerate(vocab_unique):\n",
        "    if vocab_term in doc:\n",
        "      ohe[i][j] = 1\n",
        "print(corpus_terminos)\n",
        "print(vocab_unique)\n",
        "print(ohe)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['que', 'dia', 'es', 'hoy'], ['martes', 'el', 'dia', 'de', 'hoy', 'es', 'martes'], ['martes', 'muchas', 'gracias']]\n",
            "['de' 'dia' 'el' 'es' 'gracias' 'hoy' 'martes' 'muchas' 'que']\n",
            "[[0. 1. 0. 1. 0. 1. 0. 0. 1.]\n",
            " [1. 1. 1. 1. 0. 1. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 1. 1. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIyWGmCpJVQL"
      },
      "source": [
        "### 3- Vectores de frecuencia\n",
        "Data una lista de textos, devolver una matriz con la representación de frecuencia de estos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqij_7eHJbUi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4907f01e-b601-45d0-d6e2-6fb85f4c32c4"
      },
      "source": [
        "# Tengo el corpus, el vocabulario y sus longitudes\n",
        "# Creo la matriz de OneHotEncoding\n",
        "# Recorro cada documento y con eso recorro el vocabulario, si el termino \n",
        "# del vocabulario se encuentra en el documento, modifico la matriz de datos.\n",
        "vF = np.zeros((corpus_len,vocab_len))\n",
        "\n",
        "for i,doc in enumerate(corpus_terminos):\n",
        "  for term in doc:  #for z, term in enumerate(doc):\n",
        "    for j, vocab_term in enumerate(vocab_unique):\n",
        "      if vocab_term == term:\n",
        "        vF[i][j] += 1\n",
        "\n",
        "print(corpus_terminos)\n",
        "print(vocab_unique)\n",
        "print(vF)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['que', 'dia', 'es', 'hoy'], ['martes', 'el', 'dia', 'de', 'hoy', 'es', 'martes'], ['martes', 'muchas', 'gracias']]\n",
            "['de' 'dia' 'el' 'es' 'gracias' 'hoy' 'martes' 'muchas' 'que']\n",
            "[[0. 1. 0. 1. 0. 1. 0. 0. 1.]\n",
            " [1. 1. 1. 1. 0. 1. 2. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 1. 1. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_Ot8HvWJcBu"
      },
      "source": [
        "### 4- TF-IDF\n",
        "Data una lista de textos, devolver una matriz con la representacion TFIDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "waG_oWtpJjRw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5101bef6-f652-44f5-eaa6-a23a0d998c75"
      },
      "source": [
        "N = corpus_len\n",
        "TF = np.zeros((corpus_len,vocab_len))\n",
        "IDF = np.zeros(vocab_len) # Vector de logaritmos\n",
        "TF_IDF = np.zeros((corpus_len,vocab_len))\n",
        "\n",
        "# Preparación de la matriz TF:\n",
        "for i,doc in enumerate(corpus_terminos):\n",
        "  for term in doc:  #for z, term in enumerate(doc):\n",
        "    for j, vocab_term in enumerate(vocab_unique):\n",
        "      if vocab_term == term:\n",
        "        TF[i][j] += 1\n",
        "print(\"Matriz de frecuencia:\")\n",
        "print(TF)\n",
        "\n",
        "# Vector IDF:\n",
        "for i,doc in enumerate(corpus_terminos):\n",
        "  for j,  vocab_term in enumerate(vocab_unique):\n",
        "    if vocab_term in doc:\n",
        "      IDF[j] += 1\n",
        "#IDF\n",
        "IDF = np.log10(N/IDF)\n",
        "print(\"\\nVector IDF con logaritmos aplicados: \")\n",
        "print(np.round(IDF,4))\n",
        "\n",
        "# TF_IDF:\n",
        "for i in range(len(TF_IDF)):\n",
        "  TF_IDF[i] = IDF * TF[i]\n",
        " \n",
        "print(\"\\nMatriz TF-IDF: \")\n",
        "print(np.round(TF_IDF,4))"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Matriz de frecuencia:\n",
            "[[0. 1. 0. 1. 0. 1. 0. 0. 1.]\n",
            " [1. 1. 1. 1. 0. 1. 2. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 1. 1. 0.]]\n",
            "\n",
            "Vector IDF con logaritmos aplicados: \n",
            "[0.4771 0.1761 0.4771 0.1761 0.4771 0.1761 0.1761 0.4771 0.4771]\n",
            "\n",
            "Matriz TF-IDF: \n",
            "[[0.     0.1761 0.     0.1761 0.     0.1761 0.     0.     0.4771]\n",
            " [0.4771 0.1761 0.4771 0.1761 0.     0.1761 0.3522 0.     0.    ]\n",
            " [0.     0.     0.     0.     0.4771 0.     0.1761 0.4771 0.    ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMcsfndWJjm_"
      },
      "source": [
        "### 5 - Comparación de documentos\n",
        "Realizar una funcion que reciba el corpus y el índice de un documento y devuelva los documentos ordenados por la similitud coseno"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZdiop6IJpZN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32fb1796-12d5-4aaa-da32-4846a58f2602"
      },
      "source": [
        "# se puede una matriz de 3*3 con los cosenos en todos lados\n",
        "# es para saber cual doc se parece mas a otros\n",
        "\n",
        "ohecos = np.zeros((corpus_len, corpus_len))\n",
        "for i in range(corpus_len):\n",
        "  for j in range(corpus_len):\n",
        "    ohecos[i][j] = cosine_similarity(ohe[i], ohe[j].T)\n",
        "\n",
        "vFcos = np.zeros((corpus_len, corpus_len))\n",
        "for i in range(corpus_len):\n",
        "  for j in range(corpus_len):\n",
        "    vFcos[i][j] = cosine_similarity(vF[i], vF[j].T)\n",
        "\n",
        "TF_IDFcos = np.zeros((corpus_len, corpus_len))\n",
        "for i in range(corpus_len):\n",
        "  for j in range(corpus_len):\n",
        "    TF_IDFcos[i][j] = cosine_similarity(TF_IDF[i], TF_IDF[j].T)\n",
        "print(\"Similitud coseno OHE:\")\n",
        "print(ohecos)\n",
        "print(\"\\nSimilitud coseno vector de frecuencias:\")\n",
        "print(vFcos)\n",
        "print(\"\\nSimilitud coseno TF-IDF:\")\n",
        "print(TF_IDFcos)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Similitud coseno OHE:\n",
            "[[1.         0.61237244 0.        ]\n",
            " [0.61237244 1.         0.23570226]\n",
            " [0.         0.23570226 1.        ]]\n",
            "\n",
            "Similitud coseno vector de frecuencias:\n",
            "[[1.         0.5        0.        ]\n",
            " [0.5        1.         0.38490018]\n",
            " [0.         0.38490018 1.        ]]\n",
            "\n",
            "Similitud coseno TF-IDF:\n",
            "[[1.         0.2003419  0.        ]\n",
            " [0.2003419  1.         0.10845712]\n",
            " [0.         0.10845712 1.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHRltNIN8WiZ"
      },
      "source": [
        "En las matrices anteriores se puede visualizar la relación que hay entre los distintos documentos, donde en la diagonal vemos que tanto se parece un documento consigo mismo.\n",
        "Se puede apreciar que, si bien los distintos métodos dan valores relaciones ditintas, el primer documento se asemeja en mayor medida con el segundo, luego el segundo con el tercero, y finalmente el primero con el tercero no son similares en lo absoluto."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5_yJTIu9wnj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}